{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"images/new-york.jpg\" width=\"600\"/> </td>\n",
    "<td> <img src=\"images/hollywood-sign.jpg\"  width=\"500\"/> </td>\n",
    "</tr></table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">The Big Apple vs Hollywood</h1>\n",
    "<h1 align=\"center\">(New York city vs Los Angeles)</h1>\n",
    "\n",
    "Written by A.ABDELSALAM, Oct 16 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "This report could have so many names, \"The class of the titans\", \"East vs West\", \"El classico\", but the fact is this fight over which of New York city or Los Angeles is the heart of the United States has been going on, and will most likely go on, for many years. Any of these cities alone has a tremendous influence on the rest of the world, maybe more so than any other city on this planet. From the huge impact that Wall Street has on world economics to the influence of Hollywood movies on the everyday lives of each of us, we could speak hours on end about them.  \n",
    "\n",
    "Aside from this, New York city and Los Angeles remain on the top of the lists of tourists wanting to visit for the first time the US, or for the regular tourists wanting to spend the holidays. Indeed, both are diverse and multicultural and offer a wide palette of experiences that is widely sought after by tourists. In the project we will try to group the neighbourhoods of NYC and LA respectively and draw conclusions on what they both have to offer and if one city stands out more than the other.\n",
    "\n",
    "\n",
    "# 2. Business Problem\n",
    "\n",
    "\n",
    "From a business standpoint the aim is to help tourists in choosing their destinations depending on the type of experience proposed by one or the other city. This could also help them not only decide which city to go to but what neighborhood to stay in. This could also be useful for the locals, looking to move from one city to the other, or even from any city to those two. Our analysis will hoefully provide them with a better breakdown of neighborhood compositions, in terms of culture, cuisine and facilitations. Finally, this could be the start of a more serious project for buisness owners looking to open up or branch their business.\n",
    "\n",
    "\n",
    "# 3. Data Description\n",
    "\n",
    "We will require geographical location data for both New York City and Los Angeles. The major difference is that New York city is split into boroughs and Los Angeles isn't but that should not be a problem, we will ignore the Boroughs and focus only on all the neighborhoods within New York city rather than focus on one Borough. We will essentially need a dataset that contains all the neighborhoods that exist in each city as well as the the latitude and logitude coordinates of each neighborhood.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 3.1 New York city\n",
    "\n",
    "To retrieve our data we will download it for free from this url : https://geo.nyu.edu/catalog/nyu_2451_34572\n",
    "\n",
    "The JSON file contains a lot of unecessary information and will need to be wrangled appropriately in order to extract the pertinent data. The dataset has information on the Borough as well as Neighborhood, as well as the latitude and longitude for all the neighborhoods, we will limit ouselves to only:\n",
    "1. *['features]['properties']['name']* : Name of Neighborhoods in NYC\n",
    "2. *['features]['geometry']['coordinates']* : which is a vector that contains the Latitude and Longitude of the Neighborhoods\n",
    "\n",
    "\n",
    "\n",
    "## 3.2 Los Angeles\n",
    "\n",
    "Similarily, we will download a csv readily available for free at this url : https://usc.data.socrata.com/dataset/Los-Angeles-Neighborhood-Map/r8qd-yxsr\n",
    "\n",
    "The CSV has many unecessary information but we will only retain the information we need about the neighborhoods of Los Angeles county:\n",
    "\n",
    "1. *name* : Name of Neighbourhoods in LA\n",
    "2. *latitude* : Latitude of Neighbourhoods in LA\n",
    "3. *longitude* : Longitude of Neighbourhoods in LA\n",
    "\n",
    "\n",
    "## 3.3 Foursquare API Data\n",
    "\n",
    "We will need data about different venues in the different neighbourhoods. To get that that information we will leverage the Foursquare API locational information. Foursquare is a location data provider containing information about all venues and events within an area of interest. Those information can be in the form of venue names, locations, menus, customer ratings and comments and even pictures of the venue. This makes our job easier as we can find all the information centralized in one place. Consequently we will use the foursquare location platform as our only data source since all the required information can be obtained through their API directly from the notebook.\n",
    "\n",
    "Once we have established a list of neighbourhoods, we can then connect to the Foursquare API to query for information about venues inside each and every neighbourhood. The data returned  from Foursquare query contains information of venues within a specified distance of the longitude and latitude of each neighborhood. The information foe each venue is organized as follows:\n",
    "\n",
    "1. *Neighbourhood* : Name of the Neighbourhood\n",
    "2. *Neighbourhood Latitude* : Latitude of the Neighbourhood\n",
    "3. *Neighbourhood Longitude* : Longitude of the Neighbourhood\n",
    "4. *Venue* : Name of the Venue\n",
    "5. *Venue Latitude* : Latitude of Venue\n",
    "6. *Venue Longitude* : Longitude of Venue\n",
    "7. *Venue Category* : Category of Venue\n",
    "\n",
    "For each neighbourhood, we have chosen the radius to be 500 meters and we have limited the number of returned results to 100. Indeed, with a personal free account we are limited to 99500 basic calls a day and 500 premium. This is something to take into condiseration as we will not be able to get ALL venues, and as such our data and thefore analysis will be slightly biased.\n",
    "\n",
    "Once the data for the venues of each neighborhood in NYC and LA have been gathered we will build our cluser model to group the neghborhoods according to their similarities. The rest of the report will over the methodology, data collection, wrangling, visualization and model construction. We will present and discuss our results and finish off with conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be working from within the notebook we need to set up our environment my loading all the necessary packages as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # library to handle data in a vectorized manner\n",
    "\n",
    "import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import json # library to handle JSON files\n",
    "\n",
    "#!conda install -c conda-forge geopy --yes # installs geopy if not already installed\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "import folium # map rendering library\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Data fetching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entry point of the whole project is getting the data we need from somewhere. As mentionned we will need data for both New York city and Los Angeles: those datasets need to contain a minimum of neighborhood names, which is really the bare minimum, as in fact with only this information we would be able to extract the latitudes and longitudes using other tools within Python. However it implies more work, so it is best if we initially try to get our hands on the most complete dataset in order to facilitate our coding work.\n",
    "\n",
    "For New York we will get the data in JSON format from the following URL https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/labs/newyork_data.json as shown below. It's worth mentionning that this is not the only method to handle JSON files, in fact you could directly read it into a Pandas frame, however with such dense files, you have little control over what Pandas does. In the method below we take it step by step, we take a general look at the JSON result and look for the information we need and then only put those in a dataframe.\n",
    "\n",
    "\n",
    "``` python\n",
    "# New York data\n",
    "!curl -o newyork_data.json https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/labs/newyork_data.json\n",
    "print('Data downloaded!')\n",
    "\n",
    "with open('newyork_data.json') as json_data:\n",
    "    newyork_data = json.load(json_data)  \n",
    "```\n",
    "This is what the raw data looks like :\n",
    "\n",
    "<img src=\"images/41NYraw.jpg\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Los Angeles we can manually download the CSV file and place it in our working folder. Then we can import it directly into a datafram as its structure is fairly simple.\n",
    "\n",
    "```python\n",
    "losangeles_data = pd.read_csv('la_neighborhoods.csv')\n",
    "losangeles_data.head()\n",
    "```\n",
    "This what the imported data looks like in a dataframe:\n",
    "\n",
    "<img src=\"images/4_1_LA_raw.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have imported the datasets we need to do some clean-up, also known as data wrangling in the data science world. This step is crucial inevitable if we want the rest of the project to be painless. This step can also be longer in some cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 New York city\n",
    "For New York, we notice that all the information we need is stored under the _features_ key, which is basically a list of all the neighborhoods. Hence, we will define a new variable to extract allt the _features_\n",
    "\n",
    "```python\n",
    "ny_neighborhoods_data = newyork_data['features']\n",
    "```\n",
    "\n",
    "We will then loop over all the _features_, extract the name of the neighborhoods and their locations, and store them into a dataframe that we will initialize before hand with the appropriate column names. It goes as folows:\n",
    "\n",
    "```python\n",
    "# define the dataframe columns\n",
    "column_names = ['Neighborhood', 'Latitude', 'Longitude'] \n",
    "\n",
    "# instantiate the dataframe\n",
    "ny_neighborhoods = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# loop over all the features key and store the relevant data in the df\n",
    "for data in ny_neighborhoods_data:\n",
    "    neighborhood_name = data['properties']['name']\n",
    "        \n",
    "    neighborhood_latlon = data['geometry']['coordinates']\n",
    "    neighborhood_lat = neighborhood_latlon[1]\n",
    "    neighborhood_lon = neighborhood_latlon[0]\n",
    "    \n",
    "    ny_neighborhoods = ny_neighborhoods.append({\n",
    "                                          'Neighborhood': neighborhood_name,\n",
    "                                          'Latitude': neighborhood_lat,\n",
    "                                          'Longitude': neighborhood_lon}, ignore_index=True)\n",
    "    \n",
    "```\n",
    "The result is the following dataframe: much cleaner and easier to read !\n",
    "\n",
    "<img src=\"images/4_2_NYdf.jpg\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore we can drop dupicates from the dataframe and return the number of total neighborhoods. It also very important at this early stage that we make sure there are not any null values in the latitudes and longitudes.\n",
    "\n",
    "```python\n",
    "# Getting rid of duplicates\n",
    "ny_neighborhoods = ny_neighborhoods.drop_duplicates(subset=['Neighborhood'])\n",
    "print('The dataframe has {} neighborhoods.'.format(\n",
    "        len(ny_neighborhoods['Neighborhood'].unique()),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Making sure there are no null entries\n",
    "print('There are {} and {} null entries in Latitude and Longitude'.format(ny_neighborhoods['Latitude'].isnull().sum(),ny_neighborhoods['Latitude'].isnull().sum()))\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Los Angeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Los Angeles we have already imported the dataset into a dataframe however there are plenty of useless information that we need to get rid of and lighten up the dataframe.\n",
    "\n",
    "We will select only the columns of interest to us and rename them so they match what wehave previously done with New York.\n",
    "\n",
    "We will slect only the columns with the name of the neighborhoods, their latitudes and their longitudes. We will also drop duplicates and null entries if there are any.\n",
    "\n",
    "```python\n",
    "columns_of_interest = ['name','longitude','latitude']\n",
    "la_neigborhoods = losangeles_data[columns_of_interest]\n",
    "la_neigborhoods.columns=['Neighborhood','Latitude','Longitude']\n",
    "# Droping duplicates\n",
    "la_neigborhoods = la_neigborhoods.drop_duplicates(subset=['Neighborhood'])\n",
    "\n",
    "# Checking for NaN\n",
    "la_neigborhoods.isnull().sum()\n",
    "\n",
    "```\n",
    "The result is the following dataframe\n",
    "\n",
    "<img src=\"images/4_2_LAdf.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our dataframes are ready to go, we can visualize the maps of New York and Los Angeles with their respective neighbourhoods that we collected. For this we will use the `Folium` package in Python. It's a tool that allows us to overlay pin points over specified latitudes and longitudes with a clickable popup bubble that indicates to us the name of the neighborhood.\n",
    "\n",
    "Below, the maps of New York city and its neighnorhoods\n",
    "\n",
    "<img src=\"images/4_3_NYmap.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and that of Los Angeles:\n",
    "\n",
    "<img src=\"images/4_3_LAmap.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Collecting venues information\n",
    "\n",
    "The newt step is now to explore the neighborhoods and find out what are the common venues. To accomplish this task we will use `Foursquare` as mentionned earlier. What we want to know are the types of venues, and their location for a given neighborhood. For this we will query the `Foursquare` API giving the geographical coordinates of each neighborhood, a radius of 500 meters around the neihborhood within wich we are interested in getting results, and a limit of 100 venues returned to us because we have a personal free ad therefore limited account.\n",
    "\n",
    "The function below will take in a list of neighborhood and its coordinate, will query `Foursquare` and return to us dataframe containing a list of all the venues returned by `Foursquare` for all the neighborhoods. The function is as follows :\n",
    "\n",
    "```python\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        #print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)\n",
    "\n",
    "```\n",
    "\n",
    "We will then call the function to return to us the venues in NYC and LA. Below are two snapshots of the venues dataframes.\n",
    "\n",
    "New York city venues dataframe :\n",
    "\n",
    "<img src=\"images/4_4_NYvenues.jpg\" />\n",
    "\n",
    "Los Angeles venues dataframe :\n",
    "\n",
    "<img src=\"images/4_4_LAvenues.jpg\" />\n",
    "\n",
    "We can see that we have 428 unique venue categories in New York city and 316 in Los Angeles. One could think there are many more types of venues in New York. We will only briefly discuss the difference in number, but with a simple function we can quickly have a look at the categories that are in NY but not in LA and vice versa as follows :\n",
    "\n",
    "```python\n",
    "# Define function that returns items in List 1 that are not in List 2 or vice versa\n",
    "def Diff(li1, li2): \n",
    "    return (list(set(li1)-set(li2)) ) \n",
    "\n",
    "# Categories in NY and LA\n",
    "ny_cat = ny_venues['Venue Category'].unique()\n",
    "la_cat = la_venues['Venue Category'].unique()\n",
    "\n",
    "\n",
    "ny_diff = Diff(ny_cat, la_cat)\n",
    "ny_diff\n",
    "```\n",
    "Here is a quick glance at a few things that are in NY but not in LA \"according\" to `Foursquare`\n",
    "\n",
    "<img src=\"images/4_4_nydiff.jpg\" />\n",
    "\n",
    "As you can see, without even going to either city we can immediately know that most of those venues are most definitely present in Los Angeles, and even oter cities. What we are seeing here is a different way of calling the same thing : for example, 'Bike shop' might appear in Los Angeles as 'Bicycle shop', that does not mean there aren't any bike shops in LA, just that it might be listed differenly in the Los Angeles data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 One hot encoding\n",
    "\n",
    "We have now gathered the venues withing 500 meters of each neighborhood but remember that we are interested in the most common venues let's say the top 10 venues, not just any random venue. For this we will use the one-hot-encoding method. This will allow us to convert, in some sense, the categorical data contained in the venue category into a numerical data, something that our future model can work with. Then we group the venue categories by neighborhood and take the mean of the occurence. Think of it as the probability of having a given venue in that neighborhood\n",
    "\n",
    "The process is as follows :\n",
    "\n",
    "```python\n",
    "# one hot encoding\n",
    "ny_onehot = pd.get_dummies(ny_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "ny_onehot.drop(columns=['Neighborhood'], inplace=True)\n",
    "# add neighborhood column back to dataframe\n",
    "ny_onehot['Neighborhood'] = ny_venues['Neighborhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [ny_onehot.columns[-1]] + list(ny_onehot.columns[:-1])\n",
    "ny_onehot = ny_onehot[fixed_columns]\n",
    "\n",
    "# Grouping by neighborhoods and calculating the mean for each venue type\n",
    "ny_grouped = ny_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "```\n",
    "The result is the following table for New York (the same is done for Los Angeles): \n",
    "<img src=\"images/4_5_nyonehot.jpg\" />\n",
    "\n",
    "As explained, for each neighorhood we can see the likelihood of there being a given type of venue. With this we can now move on to the next step where we can find the top 10 venues for each neighborhood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Finding the top venues\n",
    "\n",
    "Using the one hot encoded data we can now pull out the top ten venues for each neighborhood. Remember we mentionned the numerical value under each venue category is equivalent to the probability of finding this type of venue in that neighborhood. Therefore, to find the top 10 venues for each neighborhood we need to find the 10 highest venue 'probabilities'. Thereafter we want to organize that in dataframe to facilitate our analysis later on. The process is as follows:\n",
    "\n",
    "First, let's write a function to sort the venues in descending order. We will use the functions previously given in the labs\n",
    "```python\n",
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]\n",
    "```\n",
    "\n",
    "Now let's create the new dataframe and display the top 10 venues for each neighborhood.\n",
    "\n",
    "```python \n",
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "ny_neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "ny_neighborhoods_venues_sorted['Neighborhood'] = ny_grouped['Neighborhood']\n",
    "\n",
    "for ind in np.arange(ny_grouped.shape[0]):\n",
    "    ny_neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(ny_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "ny_neighborhoods_venues_sorted.head()\n",
    "```\n",
    "\n",
    "The result is as follows for New York(the same applies to Los Angeles of course) :\n",
    "\n",
    "<img src=\"images/4_6_NYtop10.jpg\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Machine learning model : kMeans Clustering\n",
    "\n",
    "We now move on to building our clustering model. The idea is to hopefully group the similar neighborhoods together. We will first need to determine the number of clusters for each city. We could make a guess but it would be better to find the optimum number of clusters by evaluating some sort of metric score for each number of clusters. This score is the ***Silhouette Coefficient*** , defined for each cluster. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a way to assess parameters like number of clusters visually. This measure has a range of [-1, 1] similarily to the linear regression score.\n",
    "\n",
    "Silhouette coefficients (as these values are referred to as) near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster.\n",
    "\n",
    "The Silhouette Coefficient is defined as such for each sample: \n",
    "\\begin{align}\n",
    "SC& = \\frac{b-a}{max(a,b)}\\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "where _a_ and _b_ are defined as follows :\n",
    "\n",
    "_a_: The mean distance between a sample and all other points in the same class.\n",
    "\n",
    "_b_: The mean distance between a sample and all other points in the next nearest cluster.\n",
    "\n",
    "\n",
    "\n",
    "Now, to find the optimal value of _k_ clusters we will loop through _1..n_ for _n_clusters_ in KMeans and calculate the average Silhouette Coefficient for each sample, we will retain the _k_ with the highest average Silhouette Coefficient.\n",
    "\n",
    "The algorithm for finding the optimal number of clusters is quite complex and will not be displayed in this report so please refer to the notebook to understand what is done behind the scene. We will only display a few samples of the Silhouette Coefficient plots and briefly comment on them.\n",
    "\n",
    "\n",
    "As it turned out, the optimal number of cluster is **_3_**, for both New York and Los Angeles. We will therefore build our two models with that in mind as follows:\n",
    "\n",
    "```python\n",
    "# Let's cluster new york in 3\n",
    "n_clusters = 3\n",
    "\n",
    "#Build our model with n_clusters = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit_predict(ny_grouped_clustering)\n",
    "```\n",
    "Once we have run our model, each neighborhood is assigned a cluster label that we will add in our dataframe and display the clusters on their respective maps.\n",
    "\n",
    "This is now what the Los Angeles dataframe looks like:\n",
    "\n",
    "<img src=\"images/4_7_LA_clusterdf.jpg\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results and Discussions\n",
    "\n",
    "\n",
    "Before diving into our analysis we will first go back to the way we computed the optimal number of clusters. In the figures below, we have on the left the Silhouette coefficient plot for each cluster within a city and on the right the clusters displayed according to their geographic position, for _k=3_ and _k=5_ . What we observe is that for _k=3_ we have most of the neighborhoods clustered in one big cluster whose silhouette coefficient is rather high with most of the silhouette curves ahead of the average silhouette coefficient represented by the dashed red line. On the other hand for _k=5_ not only is the average much lower, but there are plenty of negative coefficients. The ideal plot should have a high average coefficient and with most curves ahead of the average coefficient. Although the _k=3_ plot does not look like the ideal plot, it is the least 'bad' of all.\n",
    "\n",
    "\n",
    "<img src=\"images/4_7_NY_SC.jpg\" />\n",
    "\n",
    "<img src=\"images/4_7_NY_SC_k5.jpg\" />\n",
    "\n",
    "Let's now visualize the clusters in both cities : \n",
    "\n",
    "New York city: \n",
    "<img src=\"images/4_7_NY_cluster_map.jpg\" />\n",
    "\n",
    "Los Angeles: \n",
    "<img src=\"images/4_7_LA_cluster_map.jpg\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all looking good but in order to have a better understanding of what makes each cluster what it is, let us use wordclouds. By doing so we will see what the most common venues are with a quick glance. Below are the three wordclouds for each cluster:\n",
    "\n",
    "\n",
    "<img src=\"images/WC_NY1.jpg\" />\n",
    "<img src=\"images/WC_NY2.jpg\" />\n",
    "<img src=\"images/WC_NY3.jpg\" />\n",
    "\n",
    "and for Los Angeles:\n",
    "\n",
    "<img src=\"images/WC_LA1.jpg\" />\n",
    "<img src=\"images/WC_LA2.jpg\" />\n",
    "<img src=\"images/WC_LA3.jpg\" />\n",
    "\n",
    "What we can take from all those wordclouds is that while there are similarities there are still some differences. Both cities' neighborhoods are clearly very multicultural. Common venues are deli's and supermarkets, asian cuisine and international cuisine like turkish or peruvian. Both have parks to offer, as well as gyms and fitness centers, conveying a fit lifestyle in both cities.\n",
    "\n",
    "However, there are a few things that stand out in both cities. New York offers seems to offer have specific food venues that dominate the rest : Italian for instance, clearly under-represented in Los Angeles, which is understable given New York's immigration history. Pizza is also one of the most recurring themes, which  comes to no surprise after Italian but also because NYC is renowned for their quality pizzas. Other cuisines such as, chinese, mexican are also more dominent in New York than Los Angeles. \n",
    "\n",
    "Furthermore, we can clearly see that NYC is more of a business city than LA, we see the words _bank_, _bus_ and _station_ recurring often in NYC and not a single time in LA. Again no surprise, NYC is the financial capital of the US and has one of the best transportation system in the world.\n",
    "\n",
    "What we can say about Los Anglese, mainly from the words that do not come up in LA but are in NYC, is that it displays a more relaxed image. The word _coffee_ is also more prominent in LA, commonly associated with gatherings and the outdoors. In fact, the words _Yoga_ and fitness related words occur more often in LA, and the abscence of the word _fast-food_ conveys a healthier lifetstyle in LA. This is all most likely due to the sun.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Conclusions\n",
    "\n",
    "The purpose of this project was to explore and compare the cities of New York and Los Angeles in order to see how attractive they could be for tourists or even for people looking to immigrate or migrate to either of these two cities.\n",
    "\n",
    "We have successfully gathered and explored the data, using the available datasets online as well as the data available from _Foursquare_. We were then able to cluster the neighborhoods with a kMeans clustering model in order to better compare the two cities. \n",
    "\n",
    "What we can draw from this project is that those two cities are very much alike. Both are very multicultural, as shown by the various cuisine venues in both cities. Both are also considered to be fit cities with parks, gyms and fitness centers. \n",
    "\n",
    "There are however some differences. New york seems to have a stronger Italian and Chinese influence. This could be a selling point for immigrants from these two countries for instance. New York also seems to be more of a business city, that could be a positive point for stakeholders looking to start or expand their business. More over, New York has better transportation system, more convenient for people with no cars, student or tourists alike. In fact this could mean selling point for tourists, as renting a car in Los Angeles could turn out to be expensive and hinder the vacation budget. On the contrary, Los Angeles seems to be a healthier city, reflected by the lack of fast-food, and a more relaxed city.\n",
    "\n",
    "All in all, the results of this project have shown that while there are similarities in both cities, there are some arguments that could favor one city over the other whether one is looking to spend the holidays, or start a business or just relax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.   [Silhouette Coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)\n",
    "\n",
    "2. [Foursquare API](https://foursquare.com)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
